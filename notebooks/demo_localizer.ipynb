{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEVLocalizer â€” Minimal End-to-End Demo\n",
    "\n",
    "This notebook demonstrates the BEVLocalizer orchestrator with a synthetic database:\n",
    "- Generate a BEV image from random LiDAR-like points\n",
    "- Extract descriptors via REIN\n",
    "- Build a small retrieval index (PCA+FAISS) around the query descriptor\n",
    "- Run `BEVLocalizer.localize` and (optionally) estimate relative pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from bevplace import REIN\n",
    "from bevplace.core.types import BEVParams\n",
    "from bevplace.pipeline.localizer import BEVLocalizer\n",
    "from bevplace.preprocess.bev import bev_density_image_torch\n",
    "from bevplace.retrieval import BEVIndex\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 200, 200]), 0.0, 1.0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Make BEV from random point cloud\n",
    "params = BEVParams(D=40.0, g=0.4)\n",
    "pts = torch.randn(200000, 3, device=DEVICE) * 30.0\n",
    "bev = bev_density_image_torch(pts, params)\n",
    "bev.shape, bev.min().item(), bev.max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8192])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Extract descriptor with REIN\n",
    "model = REIN().to(DEVICE).eval()\n",
    "with torch.no_grad():\n",
    "    _, rem_map_q, q_desc = model(bev.unsqueeze(0))\n",
    "q_desc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DB size:', 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Build tiny synthetic DB around the query descriptor\n",
    "rng = np.random.default_rng(0)\n",
    "base = q_desc.detach().cpu().numpy()\n",
    "DB = np.vstack([base + rng.normal(scale=0.1, size=base.shape) for _ in range(8)])\n",
    "\n",
    "index = BEVIndex(pca_dim=16)\n",
    "index.fit_pca(DB)\n",
    "index.add(DB, poses=None)\n",
    "\"DB size:\", index._index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,\n",
       " (1,),\n",
       " 1.0,\n",
       " 2000,\n",
       " {'bev_ms': 0.8857157081365585,\n",
       "  'rein_ms': 19.770991057157516,\n",
       "  'retrieval_ms': 0.11469656601548195,\n",
       "  'pose_ms': 397.1246499568224})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Define reference provider (returns same BEV and REM map for the matched id)\n",
    "def reference_provider(_id: int):\n",
    "    return bev, rem_map_q\n",
    "\n",
    "\n",
    "localizer = BEVLocalizer(\n",
    "    model=model, index=index, bev_params=params, device=DEVICE, reference_provider=reference_provider\n",
    ")\n",
    "res = localizer.localize(pts)\n",
    "res.matched_id, res.topk, res.inliers_ratio, res.num_matches, res.timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalizationResult(pose_global=None, pose_relative=array([[1.0000000e+00, 4.0887365e-09, 0.0000000e+00],\n",
       "       [4.0887365e-09, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00]], dtype=float32), matched_id=1, topk=(1,), distances=(70.5427017211914,), inliers_ratio=1.0, num_matches=2000, timings={'bev_ms': 0.8857157081365585, 'rein_ms': 19.770991057157516, 'retrieval_ms': 0.11469656601548195, 'pose_ms': 397.1246499568224}, descriptor_q=array([[ 0.00115945, -0.00049789, -0.00434839, ..., -0.00243711,\n",
       "         0.00189914, -0.00776396]], shape=(1, 8192), dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
